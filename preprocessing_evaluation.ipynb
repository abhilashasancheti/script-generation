{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sacrebleu\n",
    "import numpy as np\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "import csv\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SEQUENCES = 5\n",
    "\n",
    "def read_finetuned(file_path):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        hypotheses = []\n",
    "        for line in lines:\n",
    "            if not line.startswith(\"==\"):\n",
    "                hypotheses.append(line.strip(' ').rstrip(' <EOS>'))\n",
    "    return hypotheses\n",
    "\n",
    "def read_pretrained(file_path):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        hypotheses = []\n",
    "        i=0\n",
    "        l=0\n",
    "        for line in lines:\n",
    "            if len(line.split())==0:\n",
    "                continue\n",
    "            elif not line.startswith(\"==\") and i>1:\n",
    "                hypotheses.append(line.strip())\n",
    "                i-=1\n",
    "            elif not line.startswith(\"==\") and i<=1:\n",
    "                hypotheses[-1] = hypotheses[-1] +\" \"+ line.strip()\n",
    "            else:\n",
    "                i+=1\n",
    "            if i==3:\n",
    "                i=2\n",
    "    return hypotheses\n",
    "\n",
    "\n",
    "def group_hypotheses(hypotheses):\n",
    "    hypotheses_basic = []\n",
    "    num_inputs = len(hypotheses)//NUM_SEQUENCES\n",
    "    for i in range(NUM_SEQUENCES):\n",
    "        hypos = []\n",
    "        for j in range(num_inputs):\n",
    "            hypos.append(hypotheses[i+(j*NUM_SEQUENCES)].strip().split(':')[1].lstrip())\n",
    "        hypotheses_basic.append(hypos)\n",
    "    return hypotheses_basic\n",
    "\n",
    "def group_ilm_hypotheses(hypotheses):\n",
    "    hypotheses_basic = []\n",
    "    num_inputs = len(hypotheses)//NUM_SEQUENCES\n",
    "    for i in range(NUM_SEQUENCES):\n",
    "        hypos = []\n",
    "        for j in range(num_inputs):\n",
    "            hypos.append(hypotheses[i+(j*NUM_SEQUENCES)].strip().split('<SEP>')[1].lstrip())\n",
    "        hypotheses_basic.append(hypos)\n",
    "    return hypotheses_basic\n",
    "\n",
    "def convert_tokens_to_basic(hypotheses_basic):\n",
    "    # convert tokens into a list\n",
    "    hypotheses_modified = []\n",
    "    for hyp in hypotheses_basic:\n",
    "        hypo = []\n",
    "        for scenario in hyp:\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            if len(events)>0:\n",
    "                h = \"\"\n",
    "                idx=0\n",
    "                for e in events:\n",
    "                    if e is not None:\n",
    "                        h+= str(idx+1) + \". \" + e.strip() + \" \"\n",
    "                        idx+=1\n",
    "                hypo.append(h.strip())\n",
    "        hypotheses_modified.append(hypo) \n",
    "    return hypotheses_modified\n",
    "\n",
    "def read_references(file_path='./data/valid_references.txt'):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        references = []\n",
    "        for line in lines:\n",
    "            ref = []\n",
    "            x = ast.literal_eval(line)\n",
    "            for i in x:\n",
    "                ref.append(\" \".join(i))\n",
    "            references.append(ref)\n",
    "    return references\n",
    "\n",
    "def read_ilm_references(file_path='./data/valid_inference_references.txt'):\n",
    "    with open(file_path) as f:\n",
    "        lines = f.readlines()\n",
    "        references = []\n",
    "        for line in lines:\n",
    "            references.append(line.strip().strip('<EOS>').strip())\n",
    "    return references\n",
    "\n",
    "def convert_refs_for_bleu(references):\n",
    "    new_references = []\n",
    "    for ref in references:\n",
    "        for idx, i in enumerate(ref):\n",
    "            if len(new_references) < 50:\n",
    "                new_references.append([i])\n",
    "            else:\n",
    "                new_references[idx].append(i)\n",
    "    return new_references\n",
    "\n",
    "\n",
    "def replace_blanks(hypotheses):\n",
    "    new_hypotheses = []\n",
    "    for hyp in hypotheses:\n",
    "        splitted_hyp = hyp.strip().split('<SEP> ')\n",
    "        scenario = splitted_hyp[0]\n",
    "        answer = splitted_hyp[1].strip().rstrip('<ANS>')\n",
    "        new_hypotheses.append(scenario.replace('<BLK>', answer).strip())\n",
    "    return new_hypotheses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = read_references(\"./data/test_references.txt\")\n",
    "new_references = convert_refs_for_bleu(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = read_pretrained('./outputs/generated_valid_ordered_large_g16_epoch1.txt')\n",
    "print(len(hypotheses))\n",
    "hypotheses_basic = group_hypotheses(hypotheses)\n",
    "hypotheses_basic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1. walk into the bathroom 2. turn on the water 3. get undressed 4. get in the shower 5. wash all over your body 6. wash your hair 7. get your hair cut 8. leave the bathroom',\n",
       " '1. go to the store 2. purchase the items needed 3. go back to the store 4. pick up the items 5. return them to the shop 6. buy the items in store 7. leave the store',\n",
       " '1. get a large box 2. take the tree out of its box 3. start the tree 4. put a small amount of soil in the soil 5. cut the branches 6. put the tree in the soil',\n",
       " '1. turn on flat tire 2. take out old tire 3. get new tire 4. put new tire into flat 5. replace old tire with new tire',\n",
       " '1. take off clothes 2. put on towel 3. sit in tub 4. take a bath 5. wash off shampoo 6. rinse shampoo 7. dry shampoo 8. use soap 9. rinse soap 10. dry soap 11. put soap in clothes 12. put on body 13. wear clothes']"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = read_finetuned('./outputs/generated_valid_ordered_large_g16_epoch1.txt')\n",
    "print(len(hypotheses))\n",
    "hypotheses_basic = group_hypotheses(hypotheses)\n",
    "hypotheses_basic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. prepare cake mix 2. put butter in pan 3. put water in pan 4. add sugar and vanilla to pan 5. wait for water to boil 6. pour batter into pan 7. stir as needed 8. check to ensure cake is cooked',\n",
       " '1. call the library and say that you want a book 2. tell the clerk that you want to borrow it 3. give them your card 4. take your book back',\n",
       " '1. park the car at the airport 2. get in the car 3. drive to the airport 4. take the proper flight ticket 5. board the airplane',\n",
       " '1. put on proper clothing 2. get in car 3. wait for train 4. get off at desired stop 5. find seat 6. sit down 7. watch or listen to the story 8. leave',\n",
       " '1. wait for bus 2. get on bus 3. find seat 4. find a seat 5. sit down 6. wait for stop 7. wait for stop 8. find a seat 9. sit down 10. start listening to music 11. get off the bus']"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses_modified = convert_tokens_to_basic(hypotheses_basic)\n",
    "hypotheses_basic = hypotheses_modified\n",
    "hypotheses_modified[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['find bicycle tire 2. drive to home 3. remove old tire from ca',\n",
       " 'remove tire. <ANS>',\n",
       " 'find flat surface. <ANS>',\n",
       " 'check to see how much rubber you need. <ANS>',\n",
       " 'find flat tire. <ANS>',\n",
       " 'remove wheel. <ANS>',\n",
       " 'find the flat on which the wheel is being repaired. <ANS>',\n",
       " 'replace wheel. <ANS>',\n",
       " 'check flat tire for flat. <ANS>',\n",
       " 'insert replacement tube into wheel. <ANS>']"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = read_finetuned('./outputs/generated_valid_large_ilm_num_ga16_epoch2_subset.txt')\n",
    "print(len(hypotheses))\n",
    "hypotheses_basic = group_ilm_hypotheses(hypotheses)\n",
    "hypotheses_basic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses_modified = []\n",
    "for hyp in hypotheses_basic:\n",
    "    hypo = []\n",
    "    for h in hyp:\n",
    "        hypo.append(\" \".join(h.strip().split(' ')[1:]))\n",
    "    hypotheses_modified.append(hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses_basic = hypotheses_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = read_ilm_references('./data/valid_inference_reference_num_subset.txt')\n",
    "# new_references = convert_refs_for_bleu(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_references = [references]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['prop bike upside down. <ANS>',\n",
       "  'prop bike upside down. <ANS>',\n",
       "  'prop bike upside down. <ANS>',\n",
       "  'prop bike upside down. <ANS>',\n",
       "  'prop bike upside down. <ANS>',\n",
       "  'prop bike upside down. <ANS>',\n",
       "  'prop bike upside down. <ANS>',\n",
       "  'prop bike upside down. <ANS>',\n",
       "  'remove wheel. <ANS>',\n",
       "  'remove wheel. <ANS>']]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores= []\n",
    "for hypothesis in hypotheses_basic:\n",
    "    scores.append(sacrebleu.corpus_bleu(hypothesis, new_references, force=True).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47.834950900413894, 2.658539775560099)"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = read_references(\"./data/test_references.txt\")\n",
    "n_references = []\n",
    "for refs in references:\n",
    "    internal = []\n",
    "    for r in refs:\n",
    "        internal.append(r.split())\n",
    "    for i in range(5):\n",
    "        n_references.append(internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. fill pan with water 2. put water in food processor 3. place cake in pan 4. turn it on 5. add butter and sugar 6. mix 7. remove from pan 8. put in to oven'"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split='test'\n",
    "prompt='ordered'\n",
    "hypotheses = read_finetuned('./outputs/generated_'+split+'_'+prompt+'_large_g16_epoch1_removed_deduplicated_ordered.txt')\n",
    "print(len(hypotheses))\n",
    "hypotheses_basic = [ hyp.strip().split(':')[1].lstrip() for hyp in hypotheses] #group_hypotheses(hypotheses)\n",
    "hypotheses_basic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1. put the water in the stove 2. put the sugar in 3. turn on the stove 4. let the sugar melt 5. pour the cake into the water 6. mix the cake and pour it into the cake molds 7. place the molds on the cake',\n",
       " '1. go to the library 2. park the car 3. find a book in a shelf 4. bring the book to the library 5. go into the library 6. sign in the appropriate area 7. find a seat 8. read the book 9. get a copy of the book 10. return the book 11. leave the library',\n",
       " '1. get in the car 2. drive to the airport 3. drive to the terminal 4. get out of car 5. wait in line 6. go through turnstiles 7. check in bags 8. check in luggage 9. go through security check in 10. board airplane',\n",
       " '1. pick a train 2. take a train 3. wait for train to arrive 4. get on a train 5. wait for train to stop',\n",
       " '1. check in 2. find a driver 3. pay for driver 4. wait for driver 5. get on the bus 6. board bus']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split='test'\n",
    "prompt='expect'\n",
    "hypotheses = read_finetuned('./outputs/generated_'+split+'_'+prompt+'_large_g16_epoch1_removed_deduplicated_ordered.txt')\n",
    "print(len(hypotheses))\n",
    "hypotheses_basic = group_hypotheses(hypotheses)\n",
    "hypotheses_basic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1. put the water in the stove 2. put the sugar in 3. turn on the stove 4. let the sugar melt 5. pour the cake into the water 6. mix the cake and pour it into the cake molds 7. place the molds on the cake',\n",
       " '1. go to the library 2. park the car 3. find a book in a shelf 4. bring the book to the library 5. go into the library 6. sign in the appropriate area 7. find a seat 8. read the book 9. get a copy of the book 10. return the book 11. leave the library',\n",
       " '1. get in the car 2. drive to the airport 3. check in luggage 4. check in bags 5. get out of car 6. drive to the terminal 7. wait in line 8. go through security check in 9. go through turnstiles 10. board airplane',\n",
       " '1. pick a train 2. take a train 3. get on a train 4. wait for train to arrive 5. wait for train to stop',\n",
       " '1. find a driver 2. pay for driver 3. check in 4. get on the bus 5. wait for driver 6. board bus']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split='test'\n",
    "prompt='expect'\n",
    "hypotheses = read_finetuned('./outputs/generated_'+split+'_'+prompt+'_large_g16_epoch1_removed.txt')\n",
    "print(len(hypotheses))\n",
    "hypotheses_basic = group_hypotheses(hypotheses)\n",
    "hypotheses_basic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1. put the water in the stove 2. put the sugar in 3. turn on the stove 4. let the sugar melt 5. pour the cake into the water 6. mix the cake and pour it into the cake molds 7. place the molds on the cake',\n",
       " '1. go to the library 2. park the car 3. find a book in a shelf 4. bring the book to the library 5. go into the library 6. sign in the appropriate area 7. find a seat 8. read the book 9. get a copy of the book 10. return the book 11. leave the library',\n",
       " '1. get in the car 2. drive to the airport 3. check in luggage 4. check in bags 5. get out of car 6. drive to the terminal 7. wait in line 8. go through security check in 9. go through turnstiles 10. board airplane',\n",
       " '1. pick a train 2. take a train 3. get on a train 4. wait for train to arrive 5. wait for train to stop',\n",
       " '1. find a driver 2. pay for driver 3. check in 4. get on the bus 5. wait for driver 6. board bus']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split='test'\n",
    "prompt='expect'\n",
    "hypotheses = read_finetuned('./outputs/generated_'+split+'_'+prompt+'_large_g16_epoch1_removed_deduplicated.txt')\n",
    "print(len(hypotheses))\n",
    "hypotheses_basic = group_hypotheses(hypotheses)\n",
    "hypotheses_basic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores= []\n",
    "for hypothesis in hypotheses_basic:\n",
    "    scores.append(corpus_bleu( n_references, [hyp.split() for hyp in hypothesis], weights=(0.25,0.25,0.25,0.25), smoothing_function=chencherry.method1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(corpus_bleu( n_references, [hyp.split() for hyp in hypotheses_basic], weights=(0.25,0.25,0.25,0.25), smoothing_function=chencherry.method1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35350554351644137, 0.10929657498666526)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.430514484397264, 1.870\n",
    "#25.323855666415096, 2.04\n",
    "#(0.2759140360672336, 0.027068697645586715) B4-avg valid removed\n",
    "# (0.2734350847838841, 0.02327469189485561 B4- normal\n",
    "# (0.27831299424721084, 0.025122564177853777) B4- removed dedup B3- (0.2111375244700135, 0.029565576897924092)\n",
    "# b2- (0.5196490011386177, 0.04002134748839136) B1- (0.8341912815176438, 0.051354008778274646)\n",
    "# (0.27300572288236225, 0.0313929603326291) b4 - all valid B1-(0.8341912815176438, 0.051354008778274646)\n",
    "# B2- (0.5149576588818612, 0.038928404112347284) B3- (0.2111438463900995, 0.031770312853950704)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Iterative BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 45.912540297281296 3.4403952558548094\n",
      "2 45.56947622190687 3.4204548515571287\n",
      "3 45.12694655547445 2.447968386056204\n",
      "4 43.976455822976774 3.0820645781642146\n",
      "5 41.817718432594965 4.451037005749699\n",
      "6 40.68770212913243 4.920513065481337\n",
      "7 40.40053468683705 4.364671329507598\n",
      "8 37.89160120977187 5.57103195401114\n",
      "9 38.97107484970193 3.9669088378543225\n",
      "10 37.382091787598405 3.5880537553788336\n"
     ]
    }
   ],
   "source": [
    "NUM_ITERATIONS=10\n",
    "references = read_references(\"./data/valid_references.txt\")\n",
    "new_references = convert_refs_for_bleu(references)\n",
    "for i in range(NUM_ITERATIONS):\n",
    "    hypotheses = read_finetuned(\"./outputs/iterative/output\"+str(i+1)+\".txt\")\n",
    "    new_outs = replace_blanks(hypotheses)\n",
    "    hypotheses_basic = group_hypotheses(new_outs)\n",
    "    scores= []\n",
    "    for hypothesis in hypotheses_basic:\n",
    "        scores.append(sacrebleu.corpus_bleu(hypothesis, new_references, force=True).score)\n",
    "    print(i+1, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence BLEU Iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. fill pan with water 2. put oil in pan 3. turn on burner on stove 4. put cake on pan 5. wait for it to harden 6. put butter in pan 7. add sugar 8. beat with a spoon 9. pour batter in pan 10. let cool for at least 30 minutes 11. eat cake 36.41462028372938\n",
      "1. go to the library 2. purchase a book 3. take a copy to the library 4. sit down in the library 5. read the book 55.93462684156708\n",
      "1. get in the car 2. drive to the airport 3. check in 4. get your ticket 5. go to the boarding gate 6. wait 7. board the airplane 74.16327246130167\n",
      "1. check where you're going to be going. 2. take a seat. 3. find a good conductor. 4. wait for train. 5. sit and enjoy the ride. 56.46714979884917\n",
      "1. find a seat 2. put on seatbelt 3. get in bus 4. find destination 38.0712823888797\n",
      "1. get a loaf of bread 2. get a pan 3. get butter, salt and sugar 4. place the pan on the stove 5. turn the stove on 6. put the bread in the pan 7. put some sugar and butter in the pan 8. turn on the stove 9. cook the cake 10. take out the pan 11. turn off the stove 12. place the pan in the trash 35.48532413372221\n",
      "1. enter library 2. pick up book 3. grab it 4. pay for book 5. get back book 38.73830120445797\n",
      "1. put on seatbelt 2. select airline and check in 3. get luggage 4. put luggage away 5. get seat 6. wait for plane 7. arrive at destination 49.05817702468361\n",
      "1. get off at stop 2. walk to the station 3. find a seat 4. wait for train 5. get off at destination 6. go home 65.28210598130448\n",
      "1. arrive at bus stop 2. get on bus 3. wait for driver 4. board the bus 5. wait for driver to arrive 6. get off bus 7. get in car 8. drive to destination 70.33575130867057\n",
      "1. measure the amount of liquid that you need to make the cake. 2. put the cake mixture in a baking pan. 3. mix the dry cake mixture with the wet cake mixture. 4. pour the mixture on top of the cake and allow it to get soggy. 5. take out the cake after a few minutes. 37.0297010809074\n",
      "1. call library 2. tell the librarian you're looking for a book 3. go to the back 4. tell librarian you're looking for a book 5. ask the librarian what book is it 6. show the book to the librarian 7. get the bill 8. return the book 9. leave library 43.84828684022183\n",
      "1. go to airport 2. go through security 3. go to the airport 4. find your seat 5. sit down 6. go back to your seat 75.72019001501822\n",
      "1. decide where you want to go. 2. get in line at station. 3. wait for train. 4. get out of line at stop. 5. find seat. 6. take your seat. 7. find a seat. 74.85669964199035\n",
      "1. wait for stop 2. buy ticket 3. get in the bus 4. wait for stop 5. get out 55.397698577004725\n",
      "1. get a pan 2. add milk and butter to pan 3. add cream and sugar 4. heat pan 5. wait for 8 to 10 minutes 6. cut in butter 32.88046464444612\n",
      "1. pick a book 2. go to the library 3. ask for the book 4. take the book 5. get the library card 6. check the book 80.47211478535493\n",
      "1. make sure plane is set up 2. go through security 3. find flight number 4. go to airplane 5. put seat belts on 6. put luggage in back 7. get into airplane 8. go to airport 9. check in 10. go to gate 11. go through security 12. wait for flight 13. get off plane 14. leave airport 47.3064017278137\n",
      "1. put on clothes 2. drive to station 3. purchase ticket 4. wait in line 5. wait for train 73.69990590777374\n",
      "1. walk to bus. 2. take your ticket. 3. pay for your ticket. 4. open your door. 5. listen to what bus driver is telling you. 6. follow the directions from the driver. 39.41983678958165\n",
      "1. decide on which kind of cake to bake. 2. go to the store and buy cake mix and mix it. 3. put the mix on a pan and pour the mixture into the pan. 4. heat the pan to the temperature of the cake. 5. add some butter in the mix. 6. turn the burner on the pan. 7. pour the batter into the pan. 8. turn the burner off the pan. 9. pour the cake mix out of the pan. 10. put the cake in a bowl. 11. eat the cake. 44.7230713604894\n",
      "1. walk up to the library 2. check out 3. take the book 4. get the book back 5. leave the library 75.39221180326287\n",
      "1. look up flights you want to take 2. decide how much you need to pay for your flight 3. go to the airline office 4. tell the sales clerk you are interested in taking a flight 5. wait for your flight 25.107059883901602\n",
      "1. get dressed 2. go to station 3. check time of train 4. purchase ticket 5. get on train 6. go through the turnstile 7. enter car 8. wait for train 9. get off when stop is reached 10. get on train 11. get off train 47.78887912835979\n",
      "1. arrive at bus stop 2. get in car 3. drive bus to stop 4. park car 5. get off bus 54.12139302088048\n"
     ]
    }
   ],
   "source": [
    "references = read_references(\"./data/test_references.txt\")\n",
    "\n",
    "hypotheses = read_finetuned(\"./outputs/generated_test_basic_large_g16_epoch1_removed.txt\")\n",
    "#new_outs = replace_blanks(hypotheses)\n",
    "new_outs = hypotheses\n",
    "hypotheses_basic = group_hypotheses(new_outs)\n",
    "scores= []\n",
    "for hypothesis in hypotheses_basic:\n",
    "    for idx, hyp in enumerate(hypothesis):\n",
    "        new_references = [[r] for r in references[idx]]\n",
    "        print(hyp, sacrebleu.corpus_bleu(hyp, new_references).score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.07765970283899"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_references = [[r] for r in references[0]]\n",
    "sacrebleu.corpus_bleu(hypotheses_basic[0][0],new_references).score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. drive to the salon 2. pay for your hair 3. get your haircut 4. get out of car 5. walk to the hair bar 6. sit down 7. wait for your cut 8. get hair cut 9. start brushing  10. wash hair with shampoo 11. dry hair with towel 12. put hair back on'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses_basic[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. look up a recipe 2. purchase ingredients 3. set out ingredients 4. preheat oven 5. being adding ingredients 6. mix 7. pour batter into pan 8. place pan into oven 9. set a timer 10. remove cake 11. frost cake 12. set cake to cool 13. enjoy a slice of cake 14. enjoy another slice of cake 15. place remainder in microwave (to store, not to cook)'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event level BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_script = {}\n",
    "dict_script[\"bake a cake\"]=\"baking a cake\"\n",
    "dict_script[\"borrow a book from the library\"]=\"borrowing a book from the library\"\n",
    "dict_script[\"change batteries in an alarm clock\"]=\"changing batteries in an alarm clock\"\n",
    "dict_script[\"fly in an airplane\"]=\"flying in an airplane\"\n",
    "dict_script[\"get a hair cut\"]=\"getting a hair cut\"\n",
    "dict_script[\"go grocery shopping\"]=\"going grocery shopping\"\n",
    "dict_script[\"go on a train\"]=\"going on a train\"\n",
    "dict_script[\"plant a tree\"]=\"planting a tree\"\n",
    "dict_script[\"repair a flat bicycle tire\"]=\"repairing a flat bicycle tire\"\n",
    "dict_script[\"ride on a bus\"]=\"riding on a bus\"\n",
    "dict_script[\"take a bath\"]=\"taking a bath\"\n",
    "dict_script[\"order fastfood online\"]= \"ordering fastfood online\"\n",
    "dict_script[\"cook in a microwave\"]=\"cooking in a microwave\"\n",
    "dict_script[\"answer telephone\"]=\"answering telephone\"\n",
    "dict_script[\"buy from a vending machine\"]=\"buying from a vending machine\"\n",
    "dict_script[\"tie shoe laces\"]=\"tying shoe laces\"\n",
    "dict_script[\"brush teeth\"]=\"brushing teeth\"\n",
    "dict_script[\"make ginger paste\"]=\"making ginger paste\"\n",
    "dict_script[\"go for a wedding\"]=\"going for a wedding\"\n",
    "dict_script[\"attend a wedding\"]=\"attending a wedding\"\n",
    "dict_script[\"wash a car\"]=\"washing a car\"\n",
    "dict_script[\"take out trash\"]=\"taking out trash\"\n",
    "dict_script[\"take a taxi\"]=\"taking a taxi\"\n",
    "dict_script[\"surf the internet\"]=\"surfing the internet\"\n",
    "dict_script[\"watch television\"] = \"watching television\"\n",
    "dict_script[\"go to a club to dance\"]=\"going to a club to dance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
    "chencherry = SmoothingFunction()\n",
    "\n",
    "def event_level_bleu_metric(in_path, scenarios):\n",
    "    with open(in_path) as f:\n",
    "        lines = f.readlines()\n",
    "        precision = []\n",
    "        coverage = []\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].rstrip(' <EOS>')\n",
    "#             print(scenario)\n",
    "            script = splitted[0].strip().replace(\"<BOS> here is an ordered sequence of events that occur when you \",\"\")\n",
    "#             print(splitted[0].strip())\n",
    "#             script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>') # direct\n",
    "#             script = splitted[0].strip().replace(\"<BOS> these are the things that happen when you \",\"\")\n",
    "#             script = splitted[0].rstrip(' <ESCR>').replace(\"<BOS> <SCR> \",\"\") # for tokens and all_tokens\n",
    "#             script = splitted[0].strip().replace(\"<BOS> describe \",\"\") # for describe\n",
    "#             script = script.replace(\" in small sequences of short sentences\",\"\") #for describe\n",
    "            new_scenario = script + \": \"\n",
    "            scenario = re.sub(r'\\d+[.]', '</bevent> <bevent>', scenario)\n",
    "            scenario = re.sub(r'<EEVENT>', '</bevent>', scenario)\n",
    "            scenario = scenario + '</bevent>'\n",
    "            scenario = scenario.strip().lstrip('</bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "#             print(scenario, soup)\n",
    "            events = []\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string.strip())\n",
    "            \n",
    "            \n",
    "            bleus=[]\n",
    "            labels=[]\n",
    "            for i in range(len(events)):\n",
    "                max_bleu = -1\n",
    "                max_label = \"\"\n",
    "                if script in scenarios:\n",
    "                    event_label = scenarios[script]\n",
    "                else:\n",
    "                    event_label = scenarios[dict_script[script]]\n",
    "                for label in event_label:\n",
    "                    bleu = sentence_bleu([ref.split() for ref in event_label[label]], events[i].strip().split(), weights=(0.25,0.25,0.25,0.25),smoothing_function=chencherry.method1)\n",
    "                    #print(bleu)\n",
    "                    if bleu > max_bleu:\n",
    "                        max_bleu = bleu\n",
    "                        max_label = label\n",
    "                bleus.append(max_bleu)\n",
    "                labels.append(max_label)\n",
    "#                 print(events,bleus, max_label)\n",
    "            coverage.append(len(list(set(labels)))/ len(list(set(event_label))))\n",
    "            precision.append(np.mean(bleus))\n",
    "        return precision, coverage\n",
    "    \n",
    "def event_level_bleu_metric_gt(script,lines, scenarios):\n",
    "    coverage = []\n",
    "    precision = []\n",
    "#     print(len(lines))\n",
    "    for scenario in lines:\n",
    "        scenario = \" \".join(scenario)\n",
    "        scenario = re.sub(r'\\d+[.]', '</bevent> <bevent>', scenario)\n",
    "        scenario = re.sub(r'<EEVENT>', '</bevent>', scenario)\n",
    "        scenario = scenario + '</bevent>'\n",
    "        scenario = scenario.strip().lstrip('</bevent>')\n",
    "        soup = BeautifulSoup(scenario)\n",
    "#         print(scenario, soup)\n",
    "        events = []\n",
    "        for a in soup.find_all('bevent'):\n",
    "            events.append(a.string.strip())\n",
    "        bleus=[]\n",
    "        labels=[]\n",
    "        for i in range(len(events)):\n",
    "            max_bleu = -1\n",
    "            max_label = \"\"\n",
    "            if script in scenarios:\n",
    "                event_label = scenarios[script]\n",
    "            else:\n",
    "                event_label = scenarios[dict_script[script]]\n",
    "            for label in event_label:\n",
    "                bleu = sentence_bleu([ref.split() for ref in event_label[label]], events[i].strip().split(), weights=(0.25,0.25,0.25,0.25),smoothing_function=chencherry.method1)\n",
    "                #print(bleu)\n",
    "                if bleu > max_bleu:\n",
    "                    max_bleu = bleu\n",
    "                    max_label = label\n",
    "            bleus.append(max_bleu)\n",
    "            labels.append(max_label)\n",
    "#                 print(events,bleus, max_label)\n",
    "        coverage.append(len(list(set(labels)))/ len(list(set(event_label))))\n",
    "        precision.append(np.mean(bleus))\n",
    "    return precision, coverage\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('paraphrase.json') as f:\n",
    "    scenarios = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scenarios[\"riding on a bus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "split='test'\n",
    "prompt='ordered'\n",
    "precision, coverage = event_level_bleu_metric('./outputs/generated_'+split+'_'+prompt+'_large_g16_epoch1.txt', scenarios)\n",
    "precision1, coverage1 = event_level_bleu_metric('./outputs/generated_'+split+'_'+prompt+'_large_g16_epoch1_removed.txt', scenarios)\n",
    "precision2, coverage2 = event_level_bleu_metric('./outputs/generated_'+split+'_'+prompt+'_large_g16_epoch1_removed_deduplicated.txt', scenarios)\n",
    "#precision3 = event_level_bleu_metric('./outputs/generated_test_basic_large_g16_epoch1_removed_deduplicated_ordered.txt', scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, coverage = event_level_bleu_metric_gt('riding on a bus', n_references[4] ,scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3 0.06030226891555274\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(coverage), np.std(coverage))\n",
    "# print(np.mean(coverage1), np.std(coverage1))\n",
    "# print(np.mean(coverage2), np.std(coverage2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35864920454615157\n",
      "0.36171876611805254\n",
      "0.35902300884906396\n"
     ]
    }
   ],
   "source": [
    "# B2\n",
    "# 0.5983247099674841\n",
    "# 0.6070936703721587\n",
    "# 0.6023631342416226\n",
    "# B1\n",
    "# 0.8354362067915369\n",
    "# 0.8396424111724123\n",
    "# 0.8380486126849779\n",
    "# B3\n",
    "# 0.40014614710363317\n",
    "# 0.40995982231730843\n",
    "# 0.40171167046915657\n",
    "# B4\n",
    "# 0.13513015022015026\n",
    "# 0.13706055315055318\n",
    "# 0.13702165871165872\n",
    "# B-Avg\n",
    "# 0.34320921226025797\n",
    "# 0.3484697176851206\n",
    "# 0.345384799039688\n",
    "print(np.mean(precision))\n",
    "print(np.mean(precision1))\n",
    "print(np.mean(precision2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B-Avg valid\n",
    "# 0.2964533926041073\n",
    "# 0.30100009824419344\n",
    "# 0.29913890204862414\n",
    "# B1\n",
    "# 0.8085896734621855\n",
    "# 0.8241745783957904\n",
    "# 0.8229712113924234\n",
    "# B2\n",
    "# 0.5552555777555778\n",
    "# 0.5663572131572132\n",
    "# 0.5666386946386947\n",
    "# B3\n",
    "# 0.27870865333234757\n",
    "# 0.2840351926790629\n",
    "# 0.2833808716914086\n",
    "# B4\n",
    "# 0.12213230241968633\n",
    "# 0.12294634122039179\n",
    "# 0.1197574523315029"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rouge Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import files2rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ref_file(refs, file_path='./ref.txt'):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for ref in refs:\n",
    "            f.write(\"{}\\n\".format(ref.strip()))\n",
    "\n",
    "def write_hyp_file(hyps, file_path='./hyp.txt'):\n",
    "    with open(file_path, 'w') as f:\n",
    "        for hyp in hyps:\n",
    "            f.write(\"{}\\n\".format(hyp.strip()))\n",
    "            \n",
    "def average_rouge(score):\n",
    "    new_dict = {'rouge-1': {'f':0, 'p':0, 'r':0}, 'rouge-2': {'f':0, 'p':0, 'r':0},'rouge-l': {'f':0, 'p':0, 'r':0}}\n",
    "    rouge1_f = []\n",
    "    rouge1_p = []\n",
    "    rouge1_r = []\n",
    "    rouge2_f = []\n",
    "    rouge2_p = []\n",
    "    rouge2_r = []\n",
    "    rougel_f = []\n",
    "    rougel_p = []\n",
    "    rougel_r = []\n",
    "    for s in score:\n",
    "        rouge1_f.append(s['rouge-1']['f'])\n",
    "        rouge1_p.append(s['rouge-1']['p'])\n",
    "        rouge1_r.append(s['rouge-1']['r'])\n",
    "        rouge2_f.append(s['rouge-2']['f'])\n",
    "        rouge2_p.append(s['rouge-2']['p'])\n",
    "        rouge2_r.append(s['rouge-2']['r'])\n",
    "        rougel_f.append(s['rouge-l']['f'])\n",
    "        rougel_p.append(s['rouge-l']['p'])\n",
    "        rougel_r.append(s['rouge-l']['r'])\n",
    "    new_dict['rouge-1']['f'] = np.mean(rouge1_f)\n",
    "    new_dict['rouge-1']['p'] = np.mean(rouge1_p)\n",
    "    new_dict['rouge-1']['r'] = np.mean(rouge1_r)\n",
    "    new_dict['rouge-2']['f'] = np.mean(rouge2_f)\n",
    "    new_dict['rouge-2']['p'] = np.mean(rouge2_p)\n",
    "    new_dict['rouge-2']['r'] = np.mean(rouge2_r)\n",
    "    new_dict['rouge-l']['f'] = np.mean(rougel_f)\n",
    "    new_dict['rouge-l']['p'] = np.mean(rougel_p)\n",
    "    new_dict['rouge-l']['r'] = np.mean(rougel_r)\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1. fill pan with water 2. put oil in pan 3. turn on burner on stove 4. put cake on pan 5. wait for it to harden 6. put butter in pan 7. add sugar 8. beat with a spoon 9. pour batter in pan 10. let cool for at least 30 minutes 11. eat cake',\n",
       " '1. go to the library 2. purchase a book 3. take a copy to the library 4. sit down in the library 5. read the book',\n",
       " '1. get in the car 2. drive to the airport 3. check in 4. get your ticket 5. go to the boarding gate 6. wait 7. board the airplane',\n",
       " \"1. check where you're going to be going. 2. take a seat. 3. find a good conductor. 4. wait for train. 5. sit and enjoy the ride.\",\n",
       " '1. find a seat 2. put on seatbelt 3. get in bus 4. find destination']"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses = read_finetuned('./outputs/generated_test_basic_large_g16_epoch1_removed.txt')\n",
    "print(len(hypotheses))\n",
    "hypotheses_basic = group_hypotheses(hypotheses)\n",
    "hypotheses_basic[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge \n",
    "rouge = Rouge()\n",
    "\n",
    "scores = []\n",
    "for hyps in hypotheses_basic:\n",
    "    score = []\n",
    "    for refs in new_references:\n",
    "        score.append(rouge.get_scores(hyps, refs, avg=True))\n",
    "    scores.append(average_rouge(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.4045293492369294,\n",
       "  'p': 0.49325946865085796,\n",
       "  'r': 0.3825668463623669},\n",
       " 'rouge-2': {'f': 0.08401757846553003,\n",
       "  'p': 0.10383870702386575,\n",
       "  'r': 0.07852581671893599},\n",
       " 'rouge-l': {'f': 0.44978031791239825,\n",
       "  'p': 0.5407590209028927,\n",
       "  'r': 0.4149776380076853}}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_rouge(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSR Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test length analysis\n",
    "with open('./scripts/data/test_references.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    length = []\n",
    "    for line in lines:\n",
    "        x = ast.literal_eval(line)\n",
    "        for hyp in x:\n",
    "            length.append(len(\" \".join(hyp).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train length analysis\n",
    "with open('./data/train.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    length = []\n",
    "    for line in lines:\n",
    "        length.append(len(line.strip().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61.28566552901024, 19.690557480899493)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(length), np.std(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.646803227808815 2.464063799834829\n",
      "8.247440273037542 2.7205202901583116\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/train_all_tokens.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    length = []\n",
    "    counts = []\n",
    "    for scenario in lines:\n",
    "        scenario = scenario.split(\":\")[1]\n",
    "        scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "        soup = BeautifulSoup(scenario)\n",
    "        #print(soup, scenario)\n",
    "        events = []\n",
    "        count=0\n",
    "        for a in soup.find_all('bevent'):\n",
    "            events.append(a.string)\n",
    "        for e in events:\n",
    "            if e is not None:\n",
    "                count+=1\n",
    "                length.append(len(e.strip().split()))\n",
    "        counts.append(count)\n",
    "\n",
    "print(np.mean(length), np.std(length))\n",
    "print(np.mean(counts), np.std(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add addditional tokens to GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "special_tokens_dict = {'bos_token': '<BOS>', 'eos_token': '<EOS>', 'pad_token': '<PAD>', 'sep_token': '<SEP>', 'additional_special_tokens': ['<ANS>','<BLK>','<SCR>','<ESCR>', '<BEVENT>', '<EEVENT>']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "tokenizer.save_pretrained('./scripts/gpt-tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add addditional tokens to Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta-tokenizer/vocab.json',\n",
       " './roberta-tokenizer/merges.txt',\n",
       " './roberta-tokenizer/special_tokens_map.json',\n",
       " './roberta-tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "special_tokens_dict = {'additional_special_tokens': ['<ANS>','<BLK>','<SCR>','<ESCR>', '<BEVENT>', '<EEVENT>']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "tokenizer.save_pretrained('./roberta-tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta-tokenizer-new/vocab.json',\n",
       " './roberta-tokenizer-new/merges.txt',\n",
       " './roberta-tokenizer-new/special_tokens_map.json',\n",
       " './roberta-tokenizer-new/added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "special_tokens_dict = {'additional_special_tokens': ['[ANS]','[BLK]','[SCR]','[ESCR]', '[BEVENT]', '[EEVENT]']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "tokenizer.save_pretrained('./roberta-tokenizer-new/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [    0, 10859,    16,    10, 13931,    9, 1061,    14,  1369,   150, 14814,    10,\n",
    "   8492,    35,   112,     4,   356,    62,    10, 10324,   132,     4,  2229,  7075,\n",
    "    155,     4,   278,   66,  7075,   204,     4,  1198, 25978, 12941,   195,     4,\n",
    "    145,  1271,  7075,   231,     4, 50266,   406,     4,  9650, 15867,    88,  5730,\n",
    "    290,     4,   317,  5730,    88, 12941,   361,     4,   278,    10, 35809,   158,\n",
    "      4,  3438,  8492,   365,     4, 18082,  8492,   316,     4,   278,  8492,     7,\n",
    "   3035,   508,     4, 50266,  1570,     4,  2254,   277, 15711,     9,  8492,   379,\n",
    "      4,   317, 11059,    11, 28562,    36,   560,  1400,     6,    45,     7,  7142,\n",
    "     43,     2,   225, 20768,    10, 15711,     9,  8492,     2, 39915,     2,     1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "special_tokens_dict = { 'cls_token': '<s>','sep_token': '</s>','additional_special_tokens': ['<ANS>','<BLK>','<SCR>','<ESCR>', '<BEVENT>', '<EEVENT>']}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./bert-tokenizer/vocab.txt',\n",
       " './bert-tokenizer/special_tokens_map.json',\n",
       " './bert-tokenizer/added_tokens.json')"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained('./bert-tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000]) tensor([0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a,b =torch.max(torch.tensor([[0.5,0.4]]),1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "def mask_sentences(in_path, out_path, prob=0.15):\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\":\")\n",
    "            scenario = splitted[1].rstrip('<EOS>')\n",
    "            script = splitted[0].lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            new_scenario = \"<BOS> here is a sequence of events that happen while \" + script.strip() + \": \"\n",
    "            answer = \"<SEP> \"\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            if len(events)>0:\n",
    "                idx=0\n",
    "                for e in events:\n",
    "                    if e is not None:\n",
    "                        mask = False\n",
    "                        if np.random.uniform(0,1) <= prob:\n",
    "                            mask = True\n",
    "                        if mask:\n",
    "                            new_scenario += \"<BLK> \"\n",
    "                            answer += str(idx+1) + \". \"+ e.strip() + \" <ANS> \"\n",
    "                        else:\n",
    "                            new_scenario += str(idx+1) + \". \" + e.strip() + \" \"\n",
    "                        idx+=1\n",
    "            o.write(\"{}\\n\".format(new_scenario + answer + \"<EOS>\"))\n",
    "            \n",
    "def mask_sentences_num(in_path, out_path, prob=0.15):\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\":\")\n",
    "            scenario = splitted[1].rstrip('<EOS>')\n",
    "            script = splitted[0].lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            new_scenario = \"<BOS> here is a sequence of events that happen while \" + script.strip() + \": \"\n",
    "            answer = \"<SEP> \"\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            if len(events)>0:\n",
    "                idx=0\n",
    "                for e in events:\n",
    "                    if e is not None:\n",
    "                        mask = False\n",
    "                        if np.random.uniform(0,1) <= prob:\n",
    "                            mask = True\n",
    "                        if mask:\n",
    "                            new_scenario += str(idx+1) + \". <BLK> \"\n",
    "                            answer +=  e.strip() + \" <ANS> \"\n",
    "                        else:\n",
    "                            new_scenario += str(idx+1) + \". \" + e.strip() + \" \"\n",
    "                        idx+=1\n",
    "            o.write(\"{}\\n\".format(new_scenario + answer + \"<EOS>\"))\n",
    "\n",
    "def mask_sentences_tokens(in_path, out_path, prob=0.15):\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\":\")\n",
    "            scenario = splitted[1].rstrip('<EOS>')\n",
    "            script = splitted[0].lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            new_scenario = \"<BOS> here is a sequence of events that happen while \" + script.strip() + \": \"\n",
    "            answer = \"<SEP> \"\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            if len(events)>0:\n",
    "                idx=0\n",
    "                for e in events:\n",
    "                    if e is not None:\n",
    "                        mask = False\n",
    "                        if np.random.uniform(0,1) <= prob:\n",
    "                            mask = True\n",
    "                        if mask:\n",
    "                            new_scenario += \"<BEVENT> <BLK> <EEVENT> \"\n",
    "                            answer +=  e.strip() + \" <ANS> \"\n",
    "                        else:\n",
    "                            new_scenario += \"<BEVENT> \" + e.strip() + \" <EEVENT> \"\n",
    "                        idx+=1\n",
    "            o.write(\"{}\\n\".format(new_scenario + answer + \"<EOS>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sentences_tokens(\"./data/train_all_tokens.txt\",\"./data/train_ilm_num_masked.txt\")\n",
    "mask_sentences_tokens(\"./data/valid_all_tokens.txt\",\"./data/valid_ilm_num_masked.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_mask_dataset(in_path, out_path, ref_path):\n",
    "    with open(in_path) as f, open(out_path, 'w') as o, open(ref_path, 'w') as r:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\":\")\n",
    "            scenario = splitted[1].rstrip('<EOS>')\n",
    "            script = splitted[0].lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            \n",
    "            for blank_id in range(len(events)):\n",
    "                new_scenario = \"<BOS> here is a sequence of events that happen while \" + script.strip() + \": \"\n",
    "                answer = \"<SEP> \"\n",
    "                reference = \"\"\n",
    "                idx=0\n",
    "                for e in events:\n",
    "                    if e is not None:\n",
    "                        if idx==blank_id:\n",
    "                            reference += e.strip() + \" <ANS> \"\n",
    "                            new_scenario += str(idx+1) + \". <BLK> \"\n",
    "                        else:\n",
    "                            new_scenario += str(idx+1) + \". \" + e.strip() + \" \"\n",
    "                        idx+=1\n",
    "                        if idx>=(blank_id+1):\n",
    "                            o.write(\"{}\\n\".format(new_scenario + answer))\n",
    "                            r.write(\"{}\\n\".format(reference + \"<EOS>\"))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_mask_dataset(\"./data/valid_all_tokens.txt\",\"./data/valid_inference_ilm_num.txt\", \"./data/valid_inference_reference_num.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations \n",
    "np.random.seed(42)\n",
    "\n",
    "def classification_data_with_num(lines, out_path):\n",
    "    with open(out_path, 'w') as o:\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario_answer = splitted[1].strip()\n",
    "            script = splitted[0].strip()\n",
    "            scenario = scenario_answer.split(\"</s>\")[0]\n",
    "            answer = \"</s> \" + scenario_answer.split(\"</s>\")[1].strip() + \" </s> \" + scenario_answer.split(\"</s>\")[2].strip()+ \" \"\n",
    "            new_scenario = script + \": \"\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>').replace('<BLK>', '[BLK]')\n",
    "            soup = BeautifulSoup(scenario)    \n",
    "#             print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string.replace('[BLK]', '<BLK>'))\n",
    "#             print(events)\n",
    "            if len(events)>0:\n",
    "                for idx, e in enumerate(events):\n",
    "                    new_scenario += str(idx+1)+ \". \" + e.strip() + \" \"\n",
    "                o.write(\"{}\\n\".format(new_scenario + answer))\n",
    "\n",
    "                    \n",
    "def classification_data(in_path, out_path):\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].rstrip('<EOS>')\n",
    "            script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            new_scenario = \"here is a sequence of events that happen while \" + script.strip() + \": \"\n",
    "            answer = \"\"\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            label = np.random.randint(0,2)\n",
    "            first=True\n",
    "            advance_event = \"\"\n",
    "            if len(events)>0:\n",
    "                eids = np.random.choice(len(events),2, replace=False)\n",
    "                for idx, e in enumerate(events):\n",
    "                    #print(idx, eids)\n",
    "                    if idx in eids:\n",
    "                        new_scenario += \"<BEVENT> <BLK> <EEVENT> \"\n",
    "                        if label==1 and first:\n",
    "                            answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                        elif label==0 and first:\n",
    "                            advance_event = \"</s> \" + e.strip() + \" \"\n",
    "                        else:\n",
    "                            answer += \"</s> \" + e.strip() + \" \"\n",
    "                        first = False\n",
    "                    else:\n",
    "                        new_scenario += \"<BEVENT> \" + e.strip() + \" <EEVENT> \"\n",
    "                answer += advance_event\n",
    "                o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "\n",
    "            \n",
    "def classification_all_combinations_data(in_path, out_path):\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].rstrip('<EOS>')\n",
    "            script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            \n",
    "            all_combinations = combinations(range(len(events)), 2)\n",
    "            if len(events)>0:\n",
    "                for eids in all_combinations:\n",
    "                    new_scenario = \"here is a sequence of events that happen while \" + script.strip() + \": \"\n",
    "                    answer = \"\"\n",
    "                    label = np.random.randint(0,2)\n",
    "                    first=True\n",
    "                    advance_event = \"\"\n",
    "                    for idx, e in enumerate(events):\n",
    "                        if idx in list(eids):\n",
    "                            new_scenario += \"<BEVENT> <BLK> <EEVENT> \"\n",
    "                            if label==1 and first:\n",
    "                                answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                            elif label==0 and first:\n",
    "                                advance_event = \"</s> \" + e.strip() + \" \"\n",
    "                            else:\n",
    "                                answer += \"</s> \" + e.strip() + \" \"\n",
    "                            first = False\n",
    "                        else:\n",
    "                            new_scenario += \"<BEVENT> \" + e.strip() + \" <EEVENT> \"\n",
    "                    answer += advance_event\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "\n",
    "def classification_all_combinations_partial_data(in_path, out_path):\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].rstrip('<EOS>')\n",
    "            script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            \n",
    "            all_combinations = combinations(range(len(events)), 2)\n",
    "            if len(events)>0:\n",
    "                for eids in all_combinations:\n",
    "                    new_scenario = script.strip() + \": \"\n",
    "                    answer = \"\"\n",
    "                    label = np.random.randint(0,2)\n",
    "                    first=True\n",
    "                    advance_event = \"\"\n",
    "                    for idx, e in enumerate(events):\n",
    "                        if idx in list(eids):\n",
    "                            if label==1 and first:\n",
    "                                answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                            elif label==0 and first:\n",
    "                                advance_event = \"</s> \" + e.strip() + \" \"\n",
    "                            else:\n",
    "                                answer += \"</s> \" + e.strip() + \" \"\n",
    "                            first = False\n",
    "                    answer += advance_event\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer + str(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification_data(\"./data/valid_all_tokens.txt\",\"./data/valid_classification.txt\")\n",
    "# classification_data(\"./data/train_all_tokens.txt\",\"./data/train_classification.txt\")\n",
    "# classification_all_combinations_data(\"./data/valid_all_tokens.txt\",\"./data/valid_classification_all.txt\")\n",
    "classification_all_combinations_partial_data(\"./data/train_all_tokens.txt\",\"./data/train_classification_partial_context_all.txt\")\n",
    "# classification_all_combinations_partial_data(\"./data/valid_all_tokens.txt\",\"./data/valid_classification_partial_context_all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train_classification.txt\") as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/train_classification.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "classification_data_with_num(lines,\"./data/train_classification_with_num.txt\")\n",
    "with open(\"./data/valid_classification.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "classification_data_with_num(lines,\"./data/valid_classification_with_num.txt\")\n",
    "with open(\"./data/test_classification.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "classification_data_with_num(lines, \"./data/test_classification_with_num.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare test data for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = read_references(\"./data/test_tokens_references.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/test_tokens.txt\") as f:\n",
    "    scenarios = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "for idx, ref in enumerate(references):\n",
    "    for r in ref:\n",
    "        lines.append(scenarios[idx].strip() + \" \" + r )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> <SCR> baking a cake <ESCR>: <BEVENT> look up a recipe <EEVENT> <BEVENT> purchase ingredients <EEVENT> <BEVENT> set out ingredients <EEVENT> <BEVENT> preheat oven <EEVENT> <BEVENT> being adding ingredients <EEVENT> <BEVENT> mix <EEVENT> <BEVENT> pour batter into pan <EEVENT> <BEVENT> place pan into oven <EEVENT> <BEVENT> set a timer <EEVENT> <BEVENT> remove cake <EEVENT> <BEVENT> frost cake <EEVENT> <BEVENT> set cake to cool <EEVENT> <BEVENT> enjoy a slice of cake <EEVENT> <BEVENT> enjoy another slice of cake <EEVENT> <BEVENT> place remainder in microwave (to store, not to cook) <EEVENT>'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification_data(lines, out_path):\n",
    "    # input is test_tokens_references\n",
    "    with open(out_path, 'w') as o:\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].strip(' ')\n",
    "#             print(scenario)\n",
    "            script = splitted[0].strip(' ').lstrip('<BOS>').strip(' ')\n",
    "            new_scenario = script.strip() + \": \"\n",
    "            answer = \"\"\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "#             print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            label = np.random.randint(0,2)\n",
    "            first=True\n",
    "            advance_event = \"\"\n",
    "            if len(events)>0:\n",
    "                eids = np.random.choice(len(events),2, replace=False)\n",
    "                for idx, e in enumerate(events):\n",
    "                    #print(idx, eids)\n",
    "                    if idx in eids:\n",
    "                        new_scenario += \"<BEVENT> <BLK> <EEVENT> \"\n",
    "                        if label==1 and first:\n",
    "                            answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                        elif label==0 and first:\n",
    "                            advance_event = \"</s> \" + e.strip() + \" \"\n",
    "                        else:\n",
    "                            answer += \"</s> \" + e.strip() + \" \"\n",
    "                        first = False\n",
    "                    else:\n",
    "                        new_scenario += \"<BEVENT> \" + e.strip() + \" <EEVENT> \"\n",
    "                answer += advance_event\n",
    "                o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "\n",
    "            \n",
    "def test_classification_all_combinations_data(lines, out_path):\n",
    "    # input is all tokens references with test.txt \n",
    "    with open(out_path, 'w') as o:\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            script = splitted[0].strip(' ').lstrip('<BOS>').strip(' ')\n",
    "            scenario = splitted[1].strip(' ')\n",
    "            new_scenario = script.strip(' ') + \": \"\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            \n",
    "            all_combinations = combinations(range(len(events)), 2)\n",
    "            if len(events)>0:\n",
    "                for eids in all_combinations:\n",
    "                    new_scenario = \"here is a sequence of events that happen while \" + script.strip() + \": \"\n",
    "                    answer = \"\"\n",
    "                    label = np.random.randint(0,2)\n",
    "                    first=True\n",
    "                    advance_event = \"\"\n",
    "                    for idx, e in enumerate(events):\n",
    "                        if idx in list(eids):\n",
    "                            new_scenario += \"<BEVENT> <BLK> <EEVENT> \"\n",
    "                            if label==1 and first:\n",
    "                                answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                            elif label==0 and first:\n",
    "                                advance_event = \"</s> \" + e.strip() + \" \"\n",
    "                            else:\n",
    "                                answer += \"</s> \" + e.strip() + \" \"\n",
    "                            first = False\n",
    "                        else:\n",
    "                            new_scenario += \"<BEVENT> \" + e.strip() + \" <EEVENT> \"\n",
    "                    answer += advance_event\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "\n",
    "def test_classification_all_combinations_partial_data_from_lines(lines, out_path):\n",
    "    # input is references from test_token_references with test.txt\n",
    "    with open(out_path, 'w') as o:\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.strip(' ').split(\": \")\n",
    "            scenario = splitted[1].strip()\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            script = splitted[0].strip().replace(\"<BOS> here is a sequence of events that happen while \",\"\")\n",
    "            new_scenario = script + \": \"\n",
    "            answer = \"<SEP> \"\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            \n",
    "            all_combinations = combinations(range(len(events)), 2)\n",
    "            if len(events)>0:\n",
    "                for eids in all_combinations:\n",
    "                    new_scenario = script.strip() + \": \"\n",
    "                    answer = \"\"\n",
    "                    label = np.random.randint(0,2)\n",
    "                    first=True\n",
    "                    advance_event = \"\"\n",
    "                    for idx, e in enumerate(events):\n",
    "                        if idx in list(eids):\n",
    "                            if label==1 and first:\n",
    "                                answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                            elif label==0 and first:\n",
    "                                advance_event = \"</s> \" + e.strip() + \" \"\n",
    "                            else:\n",
    "                                answer += \"</s> \" + e.strip() + \" \"\n",
    "                            first = False\n",
    "                    answer += advance_event\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "                    \n",
    "def test_classification_all_combinations_partial_data(in_path, out_path, prompt):\n",
    "    # input is generated output in numbered form\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].rstrip(' <EOS>')\n",
    "            if prompt=='direct':\n",
    "                script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>') # direct\n",
    "            elif prompt=='describe':\n",
    "                script = splitted[0].strip().replace(\"<BOS> describe \",\"\") # for describe\n",
    "                script = script.replace(\" in small sequences of short sentences\",\"\") #for describe \n",
    "            elif prompt=='expect':\n",
    "                script = splitted[0].strip().replace(\"<BOS> these are the things that happen when you \",\"\") # expect\n",
    "                script = dict_script[script]\n",
    "            elif prompt=='ordered':\n",
    "                script = splitted[0].strip().replace(\"<BOS> here is an ordered sequence of events that occur when you \",\"\")\n",
    "                script = dict_script[script]\n",
    "            elif prompt=='basic':\n",
    "                script = splitted[0].strip().replace(\"<BOS> here is a sequence of events that happen while \",\"\")\n",
    "            else:\n",
    "                script = splitted[0].rstrip(' <ESCR>').replace(\"<BOS> <SCR> \",\"\")\n",
    "            new_scenario = script + \": \"\n",
    "            answer = \"<SEP> \"\n",
    "            scenario = re.sub(r'\\d+[.]', '</bevent> <bevent>', scenario)\n",
    "            scenario = re.sub(r'<EEVENT>', '</bevent>', scenario)\n",
    "            scenario = scenario + '</bevent>'\n",
    "            scenario = scenario.strip().lstrip('</bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            \n",
    "            all_combinations = combinations(range(len(events)), 2)\n",
    "            if len(events)>0:\n",
    "                for eids in all_combinations:\n",
    "                    new_scenario = script.strip() + \": \"\n",
    "                    answer = \"\"\n",
    "                    label = np.random.randint(0,2)\n",
    "                    first=True\n",
    "                    advance_event = \"\"\n",
    "                    for idx, e in enumerate(events):\n",
    "                        if idx in list(eids):\n",
    "                            if label==1 and first:\n",
    "                                answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                            elif label==0 and first:\n",
    "                                advance_event = \"</s> \" + e.strip() + \" \"\n",
    "                            else:\n",
    "                                answer += \"</s> \" + e.strip() + \" \"\n",
    "                            first = False\n",
    "                    answer += advance_event\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "\n",
    "def evaluation_consecutive_ordering_data(in_path, out_path, prompt):\n",
    "    # input is generated output in numbered form\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].rstrip(' <EOS>')\n",
    "            if prompt=='direct':\n",
    "                script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>') # direct\n",
    "            elif prompt=='describe':\n",
    "                script = splitted[0].strip().replace(\"<BOS> describe \",\"\") # for describe\n",
    "                script = script.replace(\" in small sequences of short sentences\",\"\") #for describe \n",
    "            elif prompt=='expect':\n",
    "                script = splitted[0].strip().replace(\"<BOS> these are the things that happen when you \",\"\") # expect\n",
    "                script = dict_script[script]\n",
    "            elif prompt=='ordered':\n",
    "                script = splitted[0].strip().replace(\"<BOS> here is an ordered sequence of events that occur when you \",\"\")\n",
    "                script = dict_script[script]\n",
    "            elif prompt=='basic':\n",
    "                script = splitted[0].strip().replace(\"<BOS> here is a sequence of events that happen while \",\"\")\n",
    "            else:\n",
    "                script = splitted[0].rstrip(' <ESCR>').replace(\"<BOS> <SCR> \",\"\")\n",
    "\n",
    "            scenario = re.sub(r'\\d+[.]', '</bevent> <bevent>', scenario)\n",
    "            scenario = re.sub(r'<EEVENT>', '</bevent>', scenario)\n",
    "            scenario = scenario + '</bevent>'\n",
    "            scenario = scenario.strip().lstrip('</bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            \n",
    "            if len(events)>0:\n",
    "                for i in range(len(events)-1):\n",
    "                    new_scenario = script.strip() + \";\"\n",
    "                    answer = events[i].strip() + \";\" + events[i+1].strip()\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_classification_data(lines, \"./data/test_classification.txt\")\n",
    "# test_classification_data(lines, \"./data/test_classification_all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification_all_combinations_partial_data(\"./outputs/generated_valid_basic_large_g16_epoch1.txt\",\"./data/valid_classification_basic_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"describe\"\n",
    "test_classification_all_combinations_partial_data(\"./outputs/generated_valid_\"+prompt+\"_large_g16_epoch1_removed_deduplicated.txt\",\"./data/valid_classification_\"+prompt+\"_output_removed_deduplicated.txt\",prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification_all_combinations_partial_data_from_lines(lines,\"./data/test_classification_partial_context_all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='all_tokens'\n",
    "test_classification_all_combinations_partial_data(\"./outputs/generated_test_\"+prompt+\"_large_g16_epoch1_removed_deduplicated.txt\",\"./data/test_classification_\"+prompt+\"_output_removed_deduplicated.txt\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classification_all_combinations_partial_data(\"./outputs/folds/generated_new_scenarios_basic_large_fold1_g16_epoch1_removed_deduplicated.txt\",\"./data/folds/test_classification_new_scenarios_basic_large_fold1_g16_removed_deduplicated.txt\",prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='ordered'\n",
    "split=\"test\"\n",
    "evaluation_consecutive_ordering_data(\"./outputs/generated_\"+ split +\"_\"+prompt+\"_large_g16_epoch1_removed_deduplicated_ordered.txt\",\"./data/\"+split+\"_ordering.txt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_consecutive_ordering_data(\"./outputs/generated_new_scenarios_ordered.txt\",\"./data/new_scenarios_ordering.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classfication data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path):\n",
    "    with open(data_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        inputs = []\n",
    "        labels = []\n",
    "        for line in lines:\n",
    "            inputs.append(line.strip()[0:-1].strip())\n",
    "            labels.append(int(line.strip()[-1]))\n",
    "    return inputs, labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = read_data('./data/valid_classification.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys([0, 1]), dict_values([124, 126]))"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "x = Counter(labels)\n",
    "x.keys(), x.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare iterative data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = read_finetuned(\"./outputs/generated_valid_basic_large_g16_epoch1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<BOS> here is a sequence of events that happen while getting a hair cut: 1. drive to the salon 2. pay for your hair 3. get your haircut 4. get out of car 5. walk to the hair bar 6. sit down 7. wait for your cut 8. get hair cut 9. get shampoo 10. wash hair with shampoo 11. dry hair with towel 12. put hair back on'"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def iterative_mask_sentences_num(out_path, lines):\n",
    "    with open(out_path, 'w') as o:\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\":\")\n",
    "            scenario = splitted[1].rstrip('<EOS>')\n",
    "            script = splitted[0].strip()\n",
    "            new_scenario = script + \": \"\n",
    "            answer = \"<SEP> \"\n",
    "            scenario = re.sub(r'\\d+[.]', '</bevent> <bevent>', scenario)\n",
    "            scenario = scenario + '</bevent>'\n",
    "            scenario = scenario.strip().lstrip('</bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            blk = np.random.randint(0,len(events))\n",
    "            if len(events)>0:\n",
    "                for idx, e in enumerate(events):\n",
    "                    if e is not None:\n",
    "                        if idx==blk:\n",
    "                            new_scenario += str(idx+1) + \". <BLK> \"\n",
    "                            #answer +=  e.strip() + \" <ANS> \"\n",
    "                        else:\n",
    "                            new_scenario += str(idx+1) + \". \" + e.strip() + \" \"\n",
    "            o.write(\"{}\\n\".format(new_scenario + answer.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterative_mask_sentences_num(\"./outputs/iterative/input1.txt\", hypotheses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert into glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test ride bike. remove wheel. not_entailment\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open(\"./data/valid_classification_no_context.txt\") as f, open(\"../GPT/transformers/glue/RTE/dev.tsv\", 'w') as g:\n",
    "    g = csv.writer(g, delimiter='\\t')\n",
    "    lines = f.readlines()\n",
    "    g.writerow(['index', 'sentence1', 'sentence2', 'label'])\n",
    "    for idx, line in enumerate(lines):\n",
    "        sentences_label = line.strip().split(' </s> ')\n",
    "        sentence1 = sentences_label[0].strip()\n",
    "        sentence2 = sentences_label[1].strip()[0:-1].strip()\n",
    "        label = int(sentences_label[1].strip()[-1])\n",
    "        if label==0:\n",
    "            label=\"not_entailment\"\n",
    "        else:\n",
    "            label=\"entailment\"\n",
    "        if idx==0:\n",
    "            print(sentence1, sentence2, label)\n",
    "        g.writerow([idx+1, sentence1, sentence2, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../GPT/transformers/glue/MRPC/test.tsv') as g, open(\"./data/mrpc_test.txt\", 'w') as f:\n",
    "    lines = g.readlines()\n",
    "    idx = 0\n",
    "    for row in lines:\n",
    "        #print(len(row))\n",
    "        row = row.strip().split('\\t')\n",
    "        if idx==0:\n",
    "            idx+=1\n",
    "            continue\n",
    "        if len(row)==5:\n",
    "            label = int(row[0].strip())\n",
    "#             print(row)\n",
    "#             print(\"label\", label)\n",
    "#             print(\"sent1\", row[3].strip())\n",
    "#             print(\"sent2\",row[4].strip())\n",
    "#             if label==\"not_entailment\":\n",
    "#                 label= 0\n",
    "#             else:\n",
    "#                 label =1\n",
    "            f.write(\"{} </s> {} {}\\n\".format(row[3].strip().lower(), row[4].strip().lower(), label))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mrpc(in_path='./outputs/generated_test_basic_large_g16_epoch1_removed.txt', out_path_mrpc='../GPT/transformers/glue/MRPC/test.tsv', out_path_qqp='../GPT/transformers/glue/QQP/test_test.tsv'):\n",
    "    with open(in_path) as f, open(out_path_mrpc, 'w') as o, open(out_path_qqp, 'w') as p:\n",
    "        lines = f.readlines()\n",
    "        o = csv.writer(o, delimiter='\\t')\n",
    "        o.writerow(['index','#1 ID', '#2 ID', '#1 String', '#2 String'])\n",
    "        p = csv.writer(p, delimiter='\\t')\n",
    "        p.writerow(['id','question1','question2'])\n",
    "        index = 0 \n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].strip().rstrip(' <EOS>')\n",
    "            script = splitted[0].strip().replace(\"<BOS> here is a sequence of events that happen while \",\"\")\n",
    "            scenario = re.sub(r'\\d+[.]', '</bevent> <bevent>', scenario)\n",
    "            scenario = scenario + '</bevent>'\n",
    "            scenario = scenario.strip().lstrip('</bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            #print(soup, scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string.strip())\n",
    "            #print(events)\n",
    "            all_combinations = combinations(range(len(events)), 2)\n",
    "            if len(events)>0:\n",
    "                for eids in all_combinations:\n",
    "                    #print(events[eids[0]])\n",
    "                    o.writerow([index, 0,0, events[eids[0]], events[eids[1]]])  \n",
    "                    p.writerow([index, events[eids[0]], events[eids[1]]])\n",
    "                    index+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_mrpc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Classifier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "def train_relevant_classification_positive_data(in_path, out_path):\n",
    "    # input is all tokens file\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        scene_dict = {}\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].strip().rstrip('<EOS>')\n",
    "            script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            label = 1 #only positive examples now\n",
    "            if script.strip() not in scene_dict:\n",
    "                scene_dict[script.strip()] = []\n",
    "            if len(events)>0:\n",
    "                for idx, e in enumerate(events):\n",
    "                    new_scenario = script.strip() + \": \"\n",
    "                    answer = \"\"\n",
    "                    scene_dict[script.strip()].append(e.strip())\n",
    "                    answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "    return scene_dict\n",
    "\n",
    "def generated_relevant_classification_positive_data(in_path, out_path, prompt):\n",
    "    # input is generated output in numbered form\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].rstrip(' <EOS>')\n",
    "            if prompt=='direct':\n",
    "                script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>') # direct\n",
    "            elif prompt=='describe':\n",
    "                script = splitted[0].strip().replace(\"<BOS> describe \",\"\") # for describe\n",
    "                script = script.replace(\" in small sequences of short sentences\",\"\") #for describe \n",
    "            elif prompt=='expect':\n",
    "                script = splitted[0].strip().replace(\"<BOS> these are the things that happen when you \",\"\") # expect\n",
    "                script = dict_script[script]\n",
    "            elif prompt=='ordered':\n",
    "                script = splitted[0].strip().replace(\"<BOS> here is an ordered sequence of events that occur when you \",\"\")\n",
    "                script = dict_script[script]\n",
    "            elif prompt=='basic':\n",
    "                script = splitted[0].strip().replace(\"<BOS> here is a sequence of events that happen while \",\"\")\n",
    "            else:\n",
    "                script = splitted[0].rstrip(' <ESCR>').replace(\"<BOS> <SCR> \",\"\")\n",
    "            new_scenario = script + \": \"\n",
    "            scenario = re.sub(r'\\d+[.]', '</bevent> <bevent>', scenario)\n",
    "            scenario = re.sub(r'<EEVENT>', '</bevent>', scenario)\n",
    "            scenario = scenario.strip() + ' </bevent>'\n",
    "            scenario = scenario.strip().lstrip('</bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "#             print(soup)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            label = 1 #only positive examples now\n",
    "\n",
    "            if len(events)>0:\n",
    "                for idx, e in enumerate(events):\n",
    "                    new_scenario = script.strip() + \": \"\n",
    "                    answer = \"\"\n",
    "                    answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "\n",
    "def evaluation_relevant_classification_positive_data(in_path, out_path,prompt):\n",
    "    # input is generated output in numbered form\n",
    "    with open(in_path) as f, open(out_path, 'w') as o:\n",
    "        lines = f.readlines()\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].rstrip(' <EOS>')\n",
    "            if prompt=='direct':\n",
    "                script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>') # direct\n",
    "            elif prompt=='describe':\n",
    "                script = splitted[0].strip().replace(\"<BOS> describe \",\"\") # for describe\n",
    "                script = script.replace(\" in small sequences of short sentences\",\"\") #for describe \n",
    "            elif prompt=='expect':\n",
    "                script = splitted[0].strip().replace(\"<BOS> these are the things that happen when you \",\"\") # expect\n",
    "                script = dict_script[script]\n",
    "            elif prompt=='ordered':\n",
    "                script = splitted[0].strip().replace(\"<BOS> here is an ordered sequence of events that occur when you \",\"\")\n",
    "                script = dict_script[script]\n",
    "            elif prompt=='basic':\n",
    "                script = splitted[0].strip().replace(\"<BOS> here is a sequence of events that happen while \",\"\")\n",
    "            else:\n",
    "                script = splitted[0].rstrip(' <ESCR>').replace(\"<BOS> <SCR> \",\"\")\n",
    "            new_scenario = script + \": \"\n",
    "            scenario = re.sub(r'\\d+[.]', '</bevent> <bevent>', scenario)\n",
    "            scenario = re.sub(r'<EEVENT>', '</bevent>', scenario)\n",
    "            scenario = scenario.strip() + ' </bevent>'\n",
    "            scenario = scenario.strip().lstrip('</bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "#             print(soup)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "\n",
    "            if len(events)>0:\n",
    "                for idx, e in enumerate(events):\n",
    "                    new_scenario = script.strip() + \";\"\n",
    "                    answer = \"\"\n",
    "                    answer +=  e.strip() + \" \"\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer))\n",
    "\n",
    "def test_relevant_classification_positive_data(lines, out_path):\n",
    "    # input is tokens references with text.txt\n",
    "    with open(out_path, 'w') as o:\n",
    "        for scenario in lines:\n",
    "            splitted = scenario.split(\": \")\n",
    "            scenario = splitted[1].strip()\n",
    "            script = splitted[0].strip().lstrip('<BOS> <SCR> ').rstrip('<ESCR>')\n",
    "            scenario = scenario.replace('<EEVENT>','</bevent>').replace('<BEVENT>','<bevent>')\n",
    "            soup = BeautifulSoup(scenario)\n",
    "            events = []\n",
    "            count=0\n",
    "            for a in soup.find_all('bevent'):\n",
    "                events.append(a.string)\n",
    "            label = 1 #only positive examples now\n",
    "\n",
    "            if len(events)>0:\n",
    "                for idx, e in enumerate(events):\n",
    "                    new_scenario = script.strip() + \": \"\n",
    "                    answer = \"\"\n",
    "                    answer +=  \"</s> \" + e.strip() + \" \"\n",
    "                    o.write(\"{}\\n\".format(new_scenario + answer + str(label)))\n",
    "\n",
    "\n",
    "\n",
    "def train_relevant_classification_negative_data(scene_dict, out_path):\n",
    "    with open(out_path, 'a') as f:\n",
    "        scenes = list(scene_dict.keys())\n",
    "        label = 0 # negative example\n",
    "        for idx, scene in enumerate(scenes):\n",
    "            for i in range(len(scene_dict[scene])):\n",
    "                temp_scenes = copy.deepcopy(scenes)\n",
    "                temp_scenes.remove(scene) # remove the scence under consideration \n",
    "                contrastive_scene = np.random.choice(temp_scenes, 1)\n",
    "                event = np.random.choice(scene_dict[contrastive_scene[0]],1) # only onne element in the list\n",
    "                new_scenario = scene.strip() + \": \"\n",
    "                answer = \"\"\n",
    "                answer +=  \"</s> \" + event[0].strip() + \" \"\n",
    "                f.write(\"{}\\n\".format(new_scenario + answer + str(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict = train_relevant_classification_positive_data('./data/train_all_tokens.txt', './data/train_relevant_classification.txt')\n",
    "train_relevant_classification_negative_data(scene_dict, './data/train_relevant_classification.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict = train_relevant_classification_positive_data('./data/valid_all_tokens.txt', './data/valid_relevant_classification.txt')\n",
    "train_relevant_classification_negative_data(scene_dict, './data/valid_relevant_classification.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_dict = train_relevant_classification_positive_data('./data/valid_all_tokens.txt', './data/valid_relevant_classification.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_relevant_classification_positive_data(lines, './data/test_relevant_classification.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"all_tokens\"\n",
    "generated_relevant_classification_positive_data('./outputs/generated_test_'+prompt+'_large_g16_epoch1.txt', './data/test_relevant_classification_all_tokens_output.txt',prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"basic\"\n",
    "generated_relevant_classification_positive_data('./outputs/folds/generated_new_scenarios_basic_large_fold1_g16_epoch1.txt', './data/folds/test_relevant_classification_new_scenarios_basic.txt', prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train_all_tokens.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    length = [len(line.strip().split()) for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "split='test'\n",
    "prompt=\"ordered\"\n",
    "evaluation_relevant_classification_positive_data('./outputs/generated_'+split+'_'+prompt+'_large_g16_epoch1_removed_deduplicated_ordered.txt', './data/'+split+'_relevant_evaluation.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_relevant_classification_positive_data('./outputs/generated_new_scenarios_ordered.txt', './data/new_scenarios_ordered_relevant_evaluation.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle and create valid classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_val={}\n",
    "fold_val[1] = 'cooking pasta'\n",
    "fold_val[2] = 'going bowling'\n",
    "fold_val[3] = 'planting a tree'\n",
    "fold_val[4] = 'going grocery shopping'\n",
    "fold_val[5] = 'taking the underground'\n",
    "fold_val[6] = 'paying with a credit card'\n",
    "fold_val[7] = 'eating in a fast food restaurant'\n",
    "fold_val[8] = 'getting a hair cut'\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_create_valid_data():\n",
    "    for fold in range(1,9):\n",
    "        filename =  \"./data/folds/train_classification_partial_context_all_fold\"+str(fold)+\".txt\"\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        new_lines = []\n",
    "        with open(filename, 'w') as f, open(\"./data/folds/valid_classification_partial_context_all_fold\"+str(fold)+\".txt\",'w') as g:\n",
    "            for line in lines:\n",
    "#                 print(line)\n",
    "                scenario = line.strip().split(': ')[0]\n",
    "#                 print(scenario)\n",
    "                if  scenario == fold_val[fold]:\n",
    "                    g.write(\"{}\\n\".format(line.strip()))\n",
    "                else:\n",
    "                    new_lines.append(line.strip())\n",
    "            random.shuffle(new_lines)\n",
    "            for line in new_lines:\n",
    "                f.write(\"{}\\n\".format(line.strip()))\n",
    "        \n",
    "\n",
    "    # relevancy train data\n",
    "    for fold in range(1,9):\n",
    "        filename = './data/folds/train_relevant_classification_fold'+str(fold)+'.txt'\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        new_lines = []\n",
    "        with open(filename, 'w') as f, open(\"./data/folds/valid_relevant_classification_fold\"+str(fold)+\".txt\",'w') as g:\n",
    "            for line in lines:\n",
    "                if line.strip().split(': ')[0] == fold_val[fold]:\n",
    "                    g.write(\"{}\\n\".format(line.strip()))\n",
    "                else:\n",
    "                    new_lines.append(line.strip())\n",
    "            random.shuffle(new_lines)\n",
    "            for line in new_lines:\n",
    "                f.write(\"{}\\n\".format(line.strip()))           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_create_valid_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_combinations = combinations(range(8), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for eid in all_combinations:\n",
    "    a.append(eid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(len(a),1, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(NUM_SEQUENCES, 1, replace=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_fairseq",
   "language": "python",
   "name": "env_fairseq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
